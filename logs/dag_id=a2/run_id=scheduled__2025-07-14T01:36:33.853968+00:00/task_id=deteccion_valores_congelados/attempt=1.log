{"timestamp":"2025-07-14T01:36:35.741425","level":"info","event":"DAG bundles loaded: dags-folder, example_dags","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-14T01:36:35.742266","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/dag_analisis.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-14T01:36:35.792663Z","level":"info","event":"Task instance is in running state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.792880Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.QUEUED","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.793001Z","level":"info","event":"Current task name:deteccion_valores_congelados","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.793118Z","level":"info","event":"Dag name:a2","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.771831","level":"warning","event":"/opt/airflow/dags/dag_analisis.py:69: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n  df = pd.read_sql(query, conn)\n","logger":"py.warnings"}
{"timestamp":"2025-07-14T01:36:35.855763Z","level":"info","event":"        id  device_id           timestamp  value  rn","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.855982Z","level":"info","event":"0    40601          1 2025-07-08 16:30:00   0.28   3","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856105Z","level":"info","event":"1    40701          1 2025-07-08 16:45:00   0.30   2","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856218Z","level":"info","event":"2    40801          1 2025-07-08 17:00:00   0.17   1","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856330Z","level":"info","event":"3    40602          2 2025-07-08 16:30:00   0.32   3","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856443Z","level":"info","event":"4    40702          2 2025-07-08 16:45:00   0.00   2","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856553Z","level":"info","event":"..     ...        ...                 ...    ...  ..","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856665Z","level":"info","event":"295  40799         99 2025-07-08 16:45:00   0.29   2","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856788Z","level":"info","event":"296  40899         99 2025-07-08 17:00:00   0.20   1","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.856902Z","level":"info","event":"297  40700        100 2025-07-08 16:30:00   0.47   3","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.857016Z","level":"info","event":"298  40800        100 2025-07-08 16:45:00   0.51   2","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.857136Z","level":"info","event":"299  40900        100 2025-07-08 17:00:00   0.27   1","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.857250Z","level":"info","event":"","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.857358Z","level":"info","event":"[300 rows x 5 columns]","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.868705Z","level":"info","event":"todo bien","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.869877","level":"info","event":"Done. Returned value was: None","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-07-14T01:36:35.906289Z","level":"info","event":"Task instance in success state","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.906533Z","level":"info","event":" Previous state of the Task instance: TaskInstanceState.RUNNING","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-14T01:36:35.906659Z","level":"info","event":"Task operator:<Task(PythonOperator): deteccion_valores_congelados>","chan":"stdout","logger":"task"}
